from abc import ABC, abstractmethod
import os
from typing import Dict, Optional, Any, List, Union

STANDARD_GAME_PROMPT = "You are a competitive game player. Make sure you read the game instructions carefully, and always follow the required format."

# Global OpenAI client
_openai_client = None

# Config class for OpenAI API
class OpenAIConfig:
    def __init__(self, openai_api_type: str = "", openai_model: str = "", openai_api_key: str = "", openai_base_url: str = ""):
        self.TEMPERATURE = 0.7
        self.TOP_P = 1.0
        self.MAX_TOKENS_RESPONSE_GENERATION = 1024
        if openai_api_type:
            self.openai_api_type = openai_api_type
        else:
            self.openai_api_type = os.getenv("OPENAI_API_TYPE", "azure_key")
        if openai_model:
            self._openai_model = openai_model
        else:
            self._openai_model = os.getenv("OPENAI_MODEL", "gpt-4o")
        if openai_api_key:
            self._openai_api_key = openai_api_key
        else:
            self._openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if openai_base_url:
            self._openai_base_url = openai_base_url
        else:
            self._openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        
    def get_openai_model(self):
        return self._openai_model
        
    def get_openai_api_key(self):
        return self._openai_api_key
        
    def get_openai_base_url(self):
        return self._openai_base_url
        
    def set_openai_model(self, model):
        self._openai_model = model
        
    def set_openai_api_key(self, api_key):
        self._openai_api_key = api_key
        
    def set_openai_base_url(self, base_url):
        self._openai_base_url = base_url

class Agent(ABC):
    """ Generic agent class that defines the basic structure of an agent """
    @abstractmethod
    def __call__(self, observation: str) -> str:
        """
        Process the observation and return the action.

        Args:
            observation (str): The input string to process.

        Returns:
            str: The response generated by the agent.
        """
        pass

class LLMAgent(Agent):
    def __init__(self, model_name: str, device: str = "auto", quantize: bool = False, max_new_tokens: int = 1024,
                 hf_kwargs: dict = None,):
        """
        Initialize the Hugging Face local agent.
        
        Args:
            model_name (str): The name of the model.
            device (str): Device to use for model inference (default: "auto").
            quantize (bool): Whether to load the model in 8-bit quantized format (default: False).
        """
        super().__init__()
        
        try:
            from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
        except ImportError:
            raise ImportError("Transformers library is required. Install it with: pip install transformers")
            
        ## Initialize the Hugging Face model and tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        if quantize: self.model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, device_map=device, **hf_kwargs)
        else: self.model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device, **hf_kwargs)
        self.system_prompt = STANDARD_GAME_PROMPT
        self.pipeline = pipeline('text-generation', max_new_tokens=max_new_tokens, model=self.model, tokenizer=self.tokenizer) ## Initialize the Hugging Face pipeline
    
    def __call__(self, observation: str) -> str:
        """
        Process the observation using the Hugging Face model and return the action.
        
        Args:
            observation (str): The input string to process.
        
        Returns:
            str: The response generated by the model.
        """
        try: # Generate a response
            response = self.pipeline(self.system_prompt+"\n"+observation, num_return_sequences=1, return_full_text=False)
            action = response[0]['generated_text'].strip() # Extract and return the text output
            return action
        except Exception as e:
            return f"An error occurred: {e}"



class OpenAIAgent(Agent):
    """ OpenAI API-based agent class """
    def __init__(self, model_name: str = None, api_key: str = None, base_url: str = None, api_type: str = None):
        """
        Initialize the OpenAI API agent.
        
        Args:
            model_name (str, optional): The name of the OpenAI model to use.
            api_key (str, optional): OpenAI API key.
            base_url (str, optional): OpenAI API base URL.
            api_type (str, optional): API type ('azure_key' for Azure OpenAI).
        """
        super().__init__()
        
        try:
            # 确保已安装openai库
            import openai
        except ImportError:
            raise ImportError("OpenAI library is required. Install it with: pip install openai")
        
        # 创建实例自己的配置对象
        self.config = OpenAIConfig(
            openai_api_type=api_type,
            openai_model=model_name,
            openai_api_key=api_key,
            openai_base_url=base_url
        )
        
        # 记录传入的参数
        self.model_name = model_name or self.config.get_openai_model()
        
        # 检查API密钥是否已设置
        api_key = self.config.get_openai_api_key()
        if not api_key or api_key == "":
            print("Warning: OpenAI API key is not set. If needed, set it using the api_key parameter or OPENAI_API_KEY environment variable.")
            # 当使用默认设置的"123"作为空密钥标记
            self.config._openai_api_key = "123"
        
        self.system_prompt = STANDARD_GAME_PROMPT
        
        # 创建OpenAI客户端
        self._client = self._create_client()
    
    def _create_client(self):
        """创建并返回OpenAI客户端"""
        try:
            if self.config.openai_api_type == "azure_key" and self.config.get_openai_api_key() != "123":
                from openai import AzureOpenAI as OpenAI
                # Azure OpenAI需要不同的参数
                client = OpenAI(
                    azure_endpoint=self.config.get_openai_base_url(),
                    api_key=self.config.get_openai_api_key(),
                    api_version="2025-01-01-preview", 
                )
                print(f"Initialized Azure OpenAI client with endpoint: {self.config.get_openai_base_url()}")
            else:
                from openai import OpenAI
                client = OpenAI(
                    api_key=self.config.get_openai_api_key(),
                    base_url=self.config.get_openai_base_url()
                )
                print(f"Initialized standard OpenAI client with base URL: {self.config.get_openai_base_url()}")
            return client
        except Exception as e:
            print(f"Error creating OpenAI client: {e}")
            raise
    
    def __call__(self, observation: str) -> str:
        """Generate a response to the given observation
        
        Args:
            observation: The observation text from the environment
            
        Returns:
            action: The generated action text
        """
        try:
            # 准备系统提示和用户消息
            system_message = {"role": "system", "content": self.system_prompt}
            user_message = {"role": "user", "content": observation}
            
            # 记录请求信息以便调试
            print(f"Making API request to model: {self.model_name}")
            print(f"Observation length: {len(observation)} chars")
            
            # 发送请求
            response = self._client.chat.completions.create(
                model=self.model_name,
                messages=[system_message, user_message],
                temperature=self.config.TEMPERATURE,
                max_tokens=self.config.MAX_TOKENS_RESPONSE_GENERATION
            )
            
            # 提取生成的文本
            action = response.choices[0].message.content
            return action
        except Exception as e:
            # 处理错误并返回可理解的错误消息
            error_code = getattr(e, 'status_code', None)
            error_msg = f"Error code: {error_code} - {str(e)}"
            print(f"OpenAI API error: {error_msg}")
            return f"An error occurred: {error_msg}"

class HumanAgent(Agent):
    """ Human agent class that allows the user to input actions manually """
    def __init__(self):
        super().__init__()

    def __call__(self, observation: str) -> str:
        """
        Process the observation and return the action.
        
        Args:
            observation (str): The input string to process.
            
        Returns:
            str: The response generated by the agent.
        """
        print("\n\n+++ +++ +++") # for easies visualization of what is part of each turns observation
        return input(f"Current observations: {observation}\nPlease enter the action: ")